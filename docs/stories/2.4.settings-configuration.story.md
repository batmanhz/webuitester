# Story 2.4: Settings & Configuration

## Description
Provide a way for users to configure the system, specifically the LLM Backend settings (OpenAI vs. Ollama) and browser preferences.

## Acceptance Criteria
1.  **Configuration File**:
    *   System configuration is managed via `backend/config.yaml` (Already implemented in Story 2.2).
    *   Supports LLM Provider, Base URL, API Key, Model Name, and advanced parameters (Thinking, Temperature).
2.  **Settings UI (Optional/Future)**:
    *   Future: Provide manual editing of `config.yaml`.
    *   Future: Provide a UI to read/write this config file via API.
    *   Create API endpoint `GET /api/config` and `PUT /api/config` to manage `config.yaml`.
    *   Frontend Settings page to consume these endpoints.
3.  **Application**:
    *   The Backend automatically loads settings from `config.yaml` on startup.
    *   Agent uses these global settings by default.

## QA Results
### Validation Summary
- **Date**: 2026-01-03
- **Tester**: @qa (Automated Test Script)
- **Status**: **PASS**

### Test Execution Details
| Test Case ID | Description | Result | Notes |
| :--- | :--- | :--- | :--- |
| TC-2.4-001 | Verify GET /api/config endpoint | PASS | Retrieved all expected keys correctly |
| TC-2.4-002 | Verify PUT /api/config endpoint | PASS | Successfully updated configuration |
| TC-2.4-003 | Verify Parameter Persistence | PASS | Updated values (Temperature, Headless) persisted and verified |
| TC-2.4-004 | Verify Headless Mode Toggle | PASS | Headless setting correctly mapped to backend config |

### Key Observations
- The API endpoints correctly read from and write to `backend/config.yaml`.
- The in-memory settings are updated immediately upon PUT request, ensuring dynamic configuration without restart.
- Frontend Settings UI was manually verified to display and update these values correctly.
